{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNrqnSfgVAOMy6WVVSpc8XJ"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!apt update && apt upgrade\n",
        "!cd exiftool && perl Makefile.PL && make && make test && make install\n",
        "!exiftool -ver"
      ],
      "metadata": {
        "id": "DDlA-p1JpymN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRDRWoUe4pEm"
      },
      "outputs": [],
      "source": [
        "# !pip install arcticdb\n",
        "# !pip install pandas\n",
        "# !pip install pyexiftool\n",
        "from arcticdb import Arctic, QueryBuilder\n",
        "import exiftool\n",
        "import sys\n",
        "import os\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import requests\n",
        "import typing\n",
        "import subprocess\n",
        "import io\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def _handle_errors(msg):\n",
        "  print(Exception(msg))"
      ],
      "metadata": {
        "id": "eQL9A84H5Gt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ac = Arctic(f\"lmdb:///{os.getcwd()}/new_folder\")\n",
        "name_db = \"testing.arctic\"\n",
        "try:\n",
        "  ac.get_library(name_db)\n",
        "  print(\"Found lib\")\n",
        "except:\n",
        "  print(\"Not found\")\n",
        "try:\n",
        "  ac.create_library(name_db)\n",
        "  print(\"Created lib\")\n",
        "except:\n",
        "  print(\"Lib exists\")\n",
        "\n",
        "\n",
        "ac.list_libraries()"
      ],
      "metadata": {
        "id": "v5K-nuls53td"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Populating dataframe with real and public data\n",
        "\n"
      ],
      "metadata": {
        "id": "_FF7s-yXtDms"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lib = ac[name_db]\n",
        "try:\n",
        "  lib.read(\"my_data\")\n",
        "  print(\"Data already existing, skipping\")\n",
        "except:\n",
        "  try:\n",
        "    df = pd.read_csv(\"https://dados.cvm.gov.br/dados/FI/DOC/EVENTUAL/DADOS/eventual_fi_2023.csv\",sep=\";\",encoding = \"unicode_escape\")\n",
        "    print(\"Created the dataframe with cvm data\")\n",
        "  except Exception as er:\n",
        "    print(er)\n",
        "    print(\"An error occurred when trying to generate the dataframe with the cvm data, modify or let a standard dataframe be generated as shown in the docs\")\n",
        "    NUM_COLUMNS=10\n",
        "    NUM_ROWS=100_000\n",
        "    df = pd.DataFrame(np.random.randint(0,100,size=(NUM_ROWS, NUM_COLUMNS)), columns=[f\"COL_{i}\" for i in range(NUM_COLUMNS)], index=pd.date_range('2000', periods=NUM_ROWS, freq='h'))\n",
        "  lib.write(\"my_data\", df)\n",
        "# print(lib)\n",
        "# data = lib.read(\"my_data\",as_of=0)\n",
        "# print(lib.tail(\"my_data\",  5, as_of=0).data)\n",
        "\n",
        "# data = lib.read(\"my_data\")\n",
        "# print(data)\n",
        "# print(data.data)"
      ],
      "metadata": {
        "id": "p9LcCk8860pD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create query builder using arcticdb\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nw4o8f9Qs0Rg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _download_files(link: str = \"\") -> typing.Union[bytes,None]:\n",
        "    try:\n",
        "        response = requests.get(link)\n",
        "        response.raise_for_status()\n",
        "        return response\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Ocorreu um erro ao baixar o arquivo {link}: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "h7vkN670GbfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _run_exiftool_command_with_bytesio(content):\n",
        "    command = ['exiftool', '-json', '-']\n",
        "    process = subprocess.Popen(command, stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "    output, error = process.communicate(input=content)\n",
        "    return output, error"
      ],
      "metadata": {
        "id": "sVcA8s8X1fTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = QueryBuilder()\n",
        "query = query[query[\"TP_DOC\"] == \"REGUL FDO\"]\n",
        " \n",
        "data = lib.read(\"my_data\", query_builder=query).data[[\"CNPJ_FUNDO\", \"DT_RECEB\", \"TP_FUNDO\", \"LINK_ARQ\"]]\n",
        "\n",
        "for _index, _row in data.iterrows():\n",
        "  print(_row[\"LINK_ARQ\"])\n",
        "  print(_row[\"DT_RECEB\"])\n",
        "  arq = _download_files(_row[\"LINK_ARQ\"])\n",
        "  try:\n",
        "    arq_io = io.BytesIO(arq.content)\n",
        "  except:\n",
        "    print(\"An error occurred while trying to get the contents of the file\")\n",
        "    continue\n",
        "  output, error = _run_exiftool_command_with_bytesio(arq_io.getvalue())\n",
        "\n",
        "  # Verificar se ocorreu algum erro\n",
        "  if error:\n",
        "      print(f\"Erro: {error.decode('utf-8')}\")\n",
        "  else:\n",
        "      # Converter o output em um dicion√°rio\n",
        "      output_dict = json.loads(output.decode('utf-8'))\n",
        "      print(output_dict[0])\n",
        "      try:\n",
        "        data.at[_index, \"CreateDate\"] = output_dict[0][\"CreateDate\"]\n",
        "        data.at[_index, \"ModifyDate\"] = output_dict[0][\"ModifyDate\"]\n",
        "      except:\n",
        "        print(\"An error occurred while checking the parameters of CreateDate and ModifyDate\")\n",
        "  # break\n",
        "\n",
        "data"
      ],
      "metadata": {
        "id": "NzXkM9Slub7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M7sBXvgtBApC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}